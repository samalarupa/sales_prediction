{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5889,"status":"ok","timestamp":1765855478605,"user":{"displayName":"Telnozo Devs","userId":"16518007572685759980"},"user_tz":-330},"id":"zAEz1_hSoEx9","outputId":"1a268f58-378c-4e06-ce6b-389afea0c8d9"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Loading Data...\n","Data Loaded: 42172 rows, 811 products.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from prophet import Prophet\n","import lightgbm as lgb\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from sklearn.preprocessing import LabelEncoder\n","from joblib import Parallel, delayed\n","import os\n","import pickle\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","\n","# --- CONFIGURATION ---\n","CONF = {\n","    'input_file': '/content/sales_data_final.csv', # Update path\n","    'forecast_horizon_weeks': 104, # Predict next 2 years\n","    'prophet_model_dir': 'models/prophet_individual',\n","    'global_model_dir': 'models/global_lgbm',\n","    'n_jobs': -1 # Use all cores\n","}\n","\n","for d in [CONF['prophet_model_dir'], CONF['global_model_dir']]:\n","    os.makedirs(d, exist_ok=True)\n","\n","# --- 1. DATA PREPROCESSING ---\n","def load_and_clean_data(filepath):\n","    print(\">>> Loading Data...\")\n","    df = pd.read_csv(filepath)\n","\n","    # Identify date columns (assuming format YYYY-MM-DD or similar in cols)\n","    id_vars = ['Product_Code'] # Add Category if exists\n","    date_cols = [c for c in df.columns if c not in id_vars]\n","\n","    # Melt to Long Format\n","    df_long = df.melt(id_vars=id_vars, value_vars=date_cols, var_name='ds', value_name='y')\n","    df_long['ds'] = pd.to_datetime(df_long['ds'])\n","\n","    # Handle Negative/Zero Sales with Log Transform\n","    # log1p(x) = log(x + 1). This ensures 0 sales -> 0, and no negatives.\n","    df_long['y_log'] = np.log1p(df_long['y'])\n","\n","    df_long = df_long.sort_values(['Product_Code', 'ds']).reset_index(drop=True)\n","    print(f\"Data Loaded: {df_long.shape[0]} rows, {df_long['Product_Code'].nunique()} products.\")\n","    return df_long\n","\n","df_clean = load_and_clean_data(CONF['input_file'])\n","print(df_clean)\n","df_clean.to_csv('./cleaned_dataset_for_training.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":33850,"status":"error","timestamp":1765855547231,"user":{"displayName":"Telnozo Devs","userId":"16518007572685759980"},"user_tz":-330},"id":"-mJuT_rKochP","outputId":"6f93f3ad-e93c-4c0f-f4d5-84c654335572"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Starting Prophet Training for 811 products...\n","    Forecasting Horizon: 104 weeks\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4042613367.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Product_Code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m results = Parallel(n_jobs=CONF['n_jobs'], verbose=0)(\n\u001b[0m\u001b[1;32m     50\u001b[0m     delayed(train_prophet_single)(\n\u001b[1;32m     51\u001b[0m         \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Product_Code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1733\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_abort\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m             \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m             \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;34m\"\"\"Shutdown the workers and restart a new one with the same parameters\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/executor.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, kill_workers)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# When workers are killed in a brutal manner, they cannot execute the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;31m# is shutting down.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_global_shutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0mexecutor_manager_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m                 \u001b[0m_threads_wakeups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor_manager_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# --- 2. PROPHET TRAINING & BASELINE GENERATION ---\n","\n","def train_prophet_single(group, product_id, horizon):\n","    \"\"\"\n","    Trains Prophet on log-sales.\n","    Returns: DataFrame containing (ds, yhat_log, Product_Code, type='history'|'future')\n","    \"\"\"\n","    try:\n","        # Prepare data for Prophet\n","        df_p = group[['ds', 'y_log']].rename(columns={'y_log': 'y'})\n","\n","        # Force yearly seasonality because we only have 52 weeks (risky but necessary)\n","        m = Prophet(yearly_seasonality=True,\n","                    weekly_seasonality=False,\n","                    daily_seasonality=False)\n","\n","        # Add holiday effect if relevant (optional)\n","        # m.add_country_holidays(country_name='US')\n","\n","        m.fit(df_p)\n","\n","        # Save model (optional, uses disk space)\n","        with open(f\"{CONF['prophet_model_dir']}/{product_id}.pkl\", 'wb') as f:\n","            pickle.dump(m, f)\n","\n","        # Create Future Dataframe (History + Future)\n","        future = m.make_future_dataframe(periods=horizon, freq='W')\n","        forecast = m.predict(future)\n","\n","        # Clean up result\n","        forecast = forecast[['ds', 'yhat']].rename(columns={'yhat': 'prophet_pred_log'})\n","        forecast['Product_Code'] = product_id\n","\n","        # Mark rows as training or future for easy splitting later\n","        max_train_date = df_p['ds'].max()\n","        forecast['split_type'] = forecast['ds'].apply(\n","            lambda x: 'train' if x <= max_train_date else 'future'\n","        )\n","\n","        return forecast\n","    except Exception as e:\n","        print(f\"Error on {product_id}: {e}\")\n","        return pd.DataFrame()\n","\n","print(f\">>> Starting Prophet Training for {df_clean['Product_Code'].nunique()} products...\")\n","print(f\"    Forecasting Horizon: {CONF['forecast_horizon_weeks']} weeks\")\n","\n","products = df_clean['Product_Code'].unique()\n","results = Parallel(n_jobs=CONF['n_jobs'], verbose=5)(\n","    delayed(train_prophet_single)(\n","        df_clean[df_clean['Product_Code'] == p],\n","        p,\n","        CONF['forecast_horizon_weeks']\n","    ) for p in products\n",")\n","\n","# Combine all Prophet outputs\n","df_prophet_full = pd.concat(results)\n","\n","# Save intermediate file (Crucial for Phase 3 Inference)\n","df_prophet_full.to_pickle(f\"{CONF['global_model_dir']}/prophet_full_forecast.pkl\")\n","print(\">>> Phase 1 Complete. Prophet Baseline Generated.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1765829650573,"user":{"displayName":"Telnozo Devs","userId":"16518007572685759980"},"user_tz":-330},"id":"us2IEP6Dpgzw","outputId":"f2e786a8-24e0-4d95-8f36-8845e6a9e77a"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Preparing LightGBM Dataset...\n"]}],"source":["# --- 3. FEATURE ENGINEERING ---\n","\n","def create_features(df):\n","    df = df.copy()\n","\n","    # 1. Time Features\n","    df['month'] = df['ds'].dt.month\n","    df['week'] = df['ds'].dt.isocalendar().week.astype(int)\n","    df['year'] = df['ds'].dt.year\n","\n","    # 2. Cyclical Encoding (Crucial for Seasonality)\n","    # Encodes that Month 12 is close to Month 1\n","    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n","    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n","    df['week_sin'] = np.sin(2 * np.pi * df['week'] / 52)\n","    df['week_cos'] = np.cos(2 * np.pi * df['week'] / 52)\n","\n","    return df\n","\n","print(\">>> Preparing LightGBM Dataset...\")\n","\n","# Merge Prophet Predictions with Actuals for Training\n","# We only want the 'train' rows from Prophet for the LightGBM training set\n","df_train_prophet = df_prophet_full[df_prophet_full['split_type'] == 'train']\n","\n","df_ensemble = pd.merge(df_clean, df_train_prophet[['ds', 'Product_Code', 'prophet_pred_log']],\n","                       on=['ds', 'Product_Code'], how='inner')\n","\n","# Apply Feature Engineering\n","df_ensemble = create_features(df_ensemble)\n","\n","# Encode Product Code\n","le = LabelEncoder()\n","df_ensemble['Product_Code_Encoded'] = le.fit_transform(df_ensemble['Product_Code'])\n","\n","# Save Encoder\n","with open(f\"{CONF['global_model_dir']}/product_encoder.pkl\", 'wb') as f:\n","    pickle.dump(le, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4424,"status":"ok","timestamp":1765829717625,"user":{"displayName":"Telnozo Devs","userId":"16518007572685759980"},"user_tz":-330},"id":"OnxJrkqipvPv","outputId":"a4c8b007-3667-4389-d4e0-b5953178be9d"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Training Global LightGBM Model...\n","    Splitting Train/Valid at: 2025-12-09 00:00:00\n","Training until validation scores don't improve for 100 rounds\n","[200]\ttrain's rmse: 0.35173\tvalid's rmse: 0.326733\n","[400]\ttrain's rmse: 0.276265\tvalid's rmse: 0.253061\n","[600]\ttrain's rmse: 0.269306\tvalid's rmse: 0.245456\n","[800]\ttrain's rmse: 0.266424\tvalid's rmse: 0.243371\n","[1000]\ttrain's rmse: 0.264489\tvalid's rmse: 0.242897\n","Early stopping, best iteration is:\n","[1075]\ttrain's rmse: 0.263854\tvalid's rmse: 0.242791\n",">>> LightGBM Model Trained and Saved.\n"]}],"source":["# --- 4. GLOBAL LIGHTGBM TRAINING ---\n","\n","print(\">>> Training Global LightGBM Model...\")\n","\n","features = [\n","    'prophet_pred_log',\n","    'Product_Code_Encoded',\n","    'month_sin', 'month_cos',\n","    'week_sin', 'week_cos',\n","    'year'\n","]\n","target = 'y_log' # Train on Log Sales\n","\n","# Robust Time Split\n","# We sort by date. Last 4 weeks = Validation, Rest = Train.\n","unique_dates = sorted(df_ensemble['ds'].unique())\n","split_date = unique_dates[-4] # Reserve last 4 weeks for validation\n","\n","print(f\"    Splitting Train/Valid at: {split_date}\")\n","\n","train_mask = df_ensemble['ds'] <= split_date\n","valid_mask = df_ensemble['ds'] > split_date\n","\n","X_train = df_ensemble.loc[train_mask, features]\n","y_train = df_ensemble.loc[train_mask, target]\n","X_valid = df_ensemble.loc[valid_mask, features]\n","y_valid = df_ensemble.loc[valid_mask, target]\n","\n","# Create Datasets\n","dtrain = lgb.Dataset(X_train, label=y_train)\n","dvalid = lgb.Dataset(X_valid, label=y_valid, reference=dtrain)\n","\n","# Hyperparameters\n","params = {\n","    'objective': 'regression',\n","    'metric': 'rmse',\n","    'boosting_type': 'gbdt',\n","    'learning_rate': 0.01, # Lower learning rate for better generalization on small data\n","    'num_leaves': 31,\n","    'feature_fraction': 0.8,\n","    'bagging_fraction': 0.8,\n","    'bagging_freq': 5,\n","    'verbose': -1,\n","    'seed': 42\n","}\n","\n","model_lgb = lgb.train(\n","    params,\n","    dtrain,\n","    num_boost_round=2000,\n","    valid_sets=[dtrain, dvalid],\n","    valid_names=['train', 'valid'],\n","    callbacks=[\n","        lgb.early_stopping(stopping_rounds=100),\n","        lgb.log_evaluation(period=200)\n","    ]\n",")\n","\n","# Save LightGBM\n","model_lgb.save_model(f\"{CONF['global_model_dir']}/lgb_model.txt\")\n","print(\">>> LightGBM Model Trained and Saved.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79314,"status":"ok","timestamp":1765829853803,"user":{"displayName":"Telnozo Devs","userId":"16518007572685759980"},"user_tz":-330},"id":"xVjmctE7p_rG","outputId":"fc757a61-8a29-4ed0-a1ff-1d0d4e1026ea"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Generating Final Forecasts...\n","    Predicting for 84344 future rows...\n","✅ Pipeline Finished! Forecasts saved to: final_sales_forecast_2years.csv\n","           ds Product_Code  final_predicted_sales\n","52 2026-01-04           P1              12.903823\n","53 2026-01-11           P1              13.124837\n","54 2026-01-18           P1              10.717070\n","55 2026-01-25           P1               9.688339\n","56 2026-02-01           P1              11.157923\n"]}],"source":["# --- 5. INFERENCE & FORECAST GENERATION ---\n","\n","print(\">>> Generating Final Forecasts...\")\n","\n","# 1. Get the Future Prophet Data (calculated in Phase 1)\n","df_future = df_prophet_full[df_prophet_full['split_type'] == 'future'].copy()\n","\n","if df_future.empty:\n","    raise ValueError(\"No future dates found in Prophet predictions. Check Phase 1 horizon.\")\n","\n","# 2. Feature Engineering (Must be identical to Training)\n","df_future = create_features(df_future)\n","\n","# 3. Encoding\n","# Use the safe transform (handle potential new products gracefully, though unlikely here)\n","df_future['Product_Code_Encoded'] = df_future['Product_Code'].apply(\n","    lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",")\n","\n","# Filter out unknown products (if any)\n","df_future = df_future[df_future['Product_Code_Encoded'] != -1]\n","\n","# 4. LightGBM Prediction\n","print(f\"    Predicting for {df_future.shape[0]} future rows...\")\n","# Predict Log Sales\n","df_future['lgb_pred_log'] = model_lgb.predict(df_future[features])\n","\n","# 5. Inverse Transformation (Log -> Normal Sales)\n","# We clip at 0 to ensure no negatives, though expm1 usually handles this\n","df_future['final_predicted_sales'] = np.expm1(df_future['lgb_pred_log']).clip(lower=0)\n","\n","# 6. Format Final Output\n","final_submission = df_future[['ds', 'Product_Code', 'final_predicted_sales']].copy()\n","final_submission = final_submission.sort_values(['Product_Code', 'ds'])\n","\n","output_path = 'final_sales_forecast_2years.csv'\n","final_submission.to_csv(output_path, index=False)\n","\n","print(f\"✅ Pipeline Finished! Forecasts saved to: {output_path}\")\n","print(final_submission.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":738},"executionInfo":{"elapsed":250375,"status":"error","timestamp":1765833098522,"user":{"displayName":"Telnozo Devs","userId":"16518007572685759980"},"user_tz":-330},"id":"DU6UgWXhr0EP","outputId":"3685ecaf-761b-4155-fef1-cc03c0b0afcc"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Phase 1: Loading & Preprocessing...\n",">>> Phase 2: Generating Prophet Baselines (Horizon: 104 weeks)...\n",">>> Phase 3: Training Ensemble & Generating Scorecard...\n","Training until validation scores don't improve for 50 rounds\n","Early stopping, best iteration is:\n","[315]\tvalid_0's rmse: 0.239147\n","\n","========================================\n","       MODEL PERFORMANCE SCORECARD       \n","========================================\n"," Dataset Split Date : 2025-12-09 00:00:00\n","----------------------------------------\n"," R-Squared (R²)     : 0.9540  (Fit Quality)\n"," MAE                : 1.34  (Avg Error per unit)\n"," RMSE (MMSE Proxy)  : 2.22  (Penalizes large errors)\n"," WMAPE              : 15.11%\n","----------------------------------------\n"," >> ACCURACY        : 84.89% <<\n","========================================\n","\n",">>> Phase 4: Production Forecast & Database Export...\n"]},{"ename":"TypeError","evalue":"clip() got an unexpected keyword argument 'min'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4029354920.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0mdf_future\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_log'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_future\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0mdf_future\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_sales'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_future\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_log'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;31m# Format for DB (Clean Columns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mclip\u001b[0;34m(self, lower, upper, axis, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   9063\u001b[0m                     )\n\u001b[1;32m   9064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9065\u001b[0;31m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_clip_with_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9067\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/compat/numpy/function.py\u001b[0m in \u001b[0;36mvalidate_clip_with_axis\u001b[0;34m(axis, args, kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mvalidate_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# error: Incompatible return value type (got \"Union[ndarray[Any, Any],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# str, int]\", expected \"Union[str, int, None]\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/compat/numpy/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, args, kwargs, fname, max_fname_arg_count, method)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"both\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             validate_args_and_kwargs(\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fname_arg_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/_validators.py\u001b[0m in \u001b[0;36mvalidate_args_and_kwargs\u001b[0;34m(fname, args, kwargs, max_fname_arg_count, compat_args)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/_validators.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(fname, kwargs, compat_args)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \"\"\"\n\u001b[1;32m    163\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0m_check_for_invalid_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0m_check_for_default_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/_validators.py\u001b[0m in \u001b[0;36m_check_for_invalid_keys\u001b[0;34m(fname, kwargs, compat_args)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mbad_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{fname}() got an unexpected keyword argument '{bad_arg}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: clip() got an unexpected keyword argument 'min'"]}],"source":["import pandas as pd\n","import numpy as np\n","from prophet import Prophet\n","import lightgbm as lgb\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.preprocessing import LabelEncoder\n","from joblib import Parallel, delayed\n","from sqlalchemy import create_engine\n","import os\n","import pickle\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","\n","# --- CONFIGURATION ---\n","CONF = {\n","    'input_file': '/content/sales_data_final.csv',\n","    'forecast_horizon_weeks': 104,  # 2 Years\n","    'prophet_model_dir': 'models/prophet_individual',\n","    'global_model_dir': 'models/global_lgbm',\n","    'n_jobs': -1\n","}\n","\n","for d in [CONF['prophet_model_dir'], CONF['global_model_dir']]:\n","    os.makedirs(d, exist_ok=True)\n","\n","# --- 1. DATA PREPROCESSING ---\n","def load_and_clean_data(filepath):\n","    print(\">>> Phase 1: Loading & Preprocessing...\")\n","    df = pd.read_csv(filepath)\n","    id_vars = ['Product_Code']\n","    date_cols = [c for c in df.columns if c not in id_vars]\n","\n","    df_long = df.melt(id_vars=id_vars, value_vars=date_cols, var_name='ds', value_name='y')\n","    df_long['ds'] = pd.to_datetime(df_long['ds'])\n","\n","    # Log Transform for Training (Handle 0s and skew)\n","    df_long['y_log'] = np.log1p(df_long['y'])\n","\n","    df_long = df_long.sort_values(['Product_Code', 'ds']).reset_index(drop=True)\n","    return df_long\n","\n","df_clean = load_and_clean_data(CONF['input_file'])\n","\n","# --- 2. PROPHET FORECAST GENERATION (HISTORY + FUTURE) ---\n","def train_prophet_single(group, product_id, horizon):\n","    try:\n","        df_p = group[['ds', 'y_log']].rename(columns={'y_log': 'y'})\n","\n","        # Hardcoded seasonality for 52-week data\n","        m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n","        m.fit(df_p)\n","\n","        future = m.make_future_dataframe(periods=horizon, freq='W')\n","        forecast = m.predict(future)\n","\n","        forecast = forecast[['ds', 'yhat']].rename(columns={'yhat': 'prophet_pred_log'})\n","        forecast['Product_Code'] = product_id\n","\n","        max_train_date = df_p['ds'].max()\n","        forecast['split_type'] = forecast['ds'].apply(lambda x: 'train' if x <= max_train_date else 'future')\n","\n","        return forecast\n","    except Exception as e:\n","        return pd.DataFrame()\n","\n","print(f\">>> Phase 2: Generating Prophet Baselines (Horizon: {CONF['forecast_horizon_weeks']} weeks)...\")\n","results = Parallel(n_jobs=CONF['n_jobs'], verbose=0)(\n","    delayed(train_prophet_single)(df_clean[df_clean['Product_Code'] == p], p, CONF['forecast_horizon_weeks'])\n","    for p in df_clean['Product_Code'].unique()\n",")\n","df_prophet_full = pd.concat(results)\n","\n","# --- 3. FEATURE ENGINEERING ---\n","def create_features(df):\n","    df = df.copy()\n","    df['month'] = df['ds'].dt.month\n","    df['week'] = df['ds'].dt.isocalendar().week.astype(int)\n","    df['year'] = df['ds'].dt.year\n","    # Cyclical Features\n","    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n","    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n","    df['week_sin'] = np.sin(2 * np.pi * df['week'] / 52)\n","    df['week_cos'] = np.cos(2 * np.pi * df['week'] / 52)\n","    return df\n","\n","# Merge & Prepare\n","df_train_prophet = df_prophet_full[df_prophet_full['split_type'] == 'train']\n","df_ensemble = pd.merge(df_clean, df_train_prophet[['ds', 'Product_Code', 'prophet_pred_log']],\n","                       on=['ds', 'Product_Code'], how='inner')\n","df_ensemble = create_features(df_ensemble)\n","\n","le = LabelEncoder()\n","df_ensemble['Product_Code_Encoded'] = le.fit_transform(df_ensemble['Product_Code'])\n","\n","# --- 4. LIGHTGBM TRAINING & SCORECARD ---\n","print(\">>> Phase 3: Training Ensemble & Generating Scorecard...\")\n","\n","features = ['prophet_pred_log', 'Product_Code_Encoded', 'month_sin', 'month_cos', 'week_sin', 'week_cos', 'year']\n","target = 'y_log'\n","\n","# Time-based Split (Last 4 weeks for Validation)\n","unique_dates = sorted(df_ensemble['ds'].unique())\n","split_date = unique_dates[-4]\n","\n","train_mask = df_ensemble['ds'] <= split_date\n","valid_mask = df_ensemble['ds'] > split_date\n","\n","X_train, y_train = df_ensemble.loc[train_mask, features], df_ensemble.loc[train_mask, target]\n","X_valid, y_valid = df_ensemble.loc[valid_mask, features], df_ensemble.loc[valid_mask, target]\n","\n","# Train\n","model_lgb = lgb.train(\n","    {'objective': 'regression', 'metric': 'rmse', 'learning_rate': 0.02, 'verbose': -1},\n","    lgb.Dataset(X_train, label=y_train),\n","    num_boost_round=1000,\n","    valid_sets=[lgb.Dataset(X_valid, label=y_valid)],\n","    callbacks=[lgb.early_stopping(50)]\n",")\n","\n","# --- SCORECARD GENERATION ---\n","# Predict on Validation Set\n","preds_log = model_lgb.predict(X_valid)\n","preds_real = np.expm1(preds_log).clip(min=0) # Convert back to normal scale\n","actuals_real = np.expm1(y_valid).values\n","\n","# Calculate Metrics\n","mae = mean_absolute_error(actuals_real, preds_real)\n","mse = mean_squared_error(actuals_real, preds_real)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(actuals_real, preds_real)\n","\n","# WMAPE Calculation (Sum of Absolute Errors / Sum of Actuals)\n","wmape = np.sum(np.abs(actuals_real - preds_real)) / np.sum(actuals_real)\n","accuracy = 1.0 - wmape\n","\n","print(\"\\n\" + \"=\"*40)\n","print(\"       MODEL PERFORMANCE SCORECARD       \")\n","print(\"=\"*40)\n","print(f\" Dataset Split Date : {split_date}\")\n","print(\"-\" * 40)\n","print(f\" R-Squared (R²)     : {r2:.4f}  (Fit Quality)\")\n","print(f\" MAE                : {mae:.2f}  (Avg Error per unit)\")\n","print(f\" RMSE (MMSE Proxy)  : {rmse:.2f}  (Penalizes large errors)\")\n","print(f\" WMAPE              : {wmape:.2%}\")\n","print(\"-\" * 40)\n","print(f\" >> ACCURACY        : {accuracy:.2%} <<\")\n","print(\"=\"*40 + \"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73955,"status":"ok","timestamp":1765833288973,"user":{"displayName":"Telnozo Devs","userId":"16518007572685759980"},"user_tz":-330},"id":"8WrNs7pS24uJ","outputId":"ce8637ab-52cd-444e-b5b3-9c5ac1bf24fe"},"outputs":[{"name":"stdout","output_type":"stream","text":[">>> Phase 4: Production Forecast & Database Export...\n","❌ Database Error: (psycopg2.OperationalError) could not translate host name \"1912@db.vrxpfivbtfzsltxqlbwu.supabase.co\" to address: Name or service not known\n","\n","(Background on this error at: https://sqlalche.me/e/20/e3q8)\n","   (Check your connection string in CONF)\n"]}],"source":["\n","# --- 5. FINAL FORECAST & DB EXPORT ---\n","print(\">>> Phase 4: Production Forecast & Database Export...\")\n","\n","# Prepare Future Data\n","df_future = df_prophet_full[df_prophet_full['split_type'] == 'future'].copy()\n","df_future = create_features(df_future)\n","df_future['Product_Code_Encoded'] = df_future['Product_Code'].apply(\n","    lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",")\n","df_future = df_future[df_future['Product_Code_Encoded'] != -1]\n","\n","# Predict\n","df_future['predicted_log'] = model_lgb.predict(df_future[features])\n","df_future['predicted_sales'] = np.expm1(df_future['predicted_log']).clip(lower=0)\n","\n","# Format for DB (Clean Columns)\n","df_export = df_future[['ds', 'Product_Code', 'predicted_sales']].rename(\n","    columns={'ds': 'forecast_date', 'Product_Code': 'product_code'}\n",")\n","\n","# Also save CSV as backup\n","df_export.to_csv('final_forecast_backup.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1765833135206,"user":{"displayName":"Telnozo Devs","userId":"16518007572685759980"},"user_tz":-330},"id":"I78gZ8jM1SU5","outputId":"610233cd-053c-47a5-d8d6-cc92a577f5d6"},"outputs":[{"data":{"text/plain":["<lightgbm.basic.Booster at 0x7c14c663b4a0>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["model_lgb.save_model('./trained_lgb_model_for_metrics.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AaMPTxPUw08q"},"outputs":[],"source":["df_ensemble.to_csv('./latest_df_ensemble.csv')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMCf6pfuipid2wX4zQofaGp","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
